{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Assignment 4: Analyzing Sentiment\n",
    "Tyler Bevan\n",
    "\n",
    " * some data: http://help.sentiment140.com/for-students\n",
    "\n",
    "**Columns:**\n",
    "\n",
    "    0 - the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "    1 - the id of the tweet (2087)\n",
    "    2 - the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "    3 - the query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "    4 - the user that tweeted (robotickilldozr)\n",
    "    5 - the text of the tweet (Lyx is cool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tbevan\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn import linear_model\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import *\n",
    "import gensim.models.keyedvectors as w\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the data has already been split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data 1600000\n"
     ]
    }
   ],
   "source": [
    "cols = ['polarity','id', 'date', 'query', 'user', 'tweet']\n",
    "\n",
    "data = pd.read_csv('sentiment.csv',names=cols, encoding='ISO-8859-1')\n",
    "print('length of data {}'.format(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a lot of data. That's great! However, it will take a long time to get through this notebook with all of that data, so I'm going to randomly choose about 10% of it. We also don't need all of those columns, so let's only keep the ones we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity                                              tweet\n",
       "0         0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1         0  is upset that he can't update his Facebook by ...\n",
       "2         0  @Kenichan I dived many times for the ball. Man..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data=data.sample(frac=0.1,random_state=200)\n",
    "data = data.drop(['id', 'date', 'query', 'user'], axis=1)\n",
    "data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many of each type are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 4}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) How many of each polarity are there?\n",
    "\n",
    "* Hint: use a mask over the `data` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 800000, 4: 800000})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = Counter(data.polarity)\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) Change all 4s in polarity to 1\n",
    "\n",
    "* Hint: a lambda function might be useful here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_to_one(x):\n",
    "    return 1 if x == 4 else x\n",
    "    \n",
    "data['polarity'] = data.polarity.map(four_to_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 800000, 1: 800000})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = Counter(data.polarity)\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) split the data into 10% test, 10% and 80% train\n",
    "\n",
    "* create `test`, `dev`, and `train` data tables\n",
    "* you can use the `.sample()` method for the dataframe\n",
    "* print out the shapes of each of the three tables\n",
    "* What is the baseline for this task? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1280000, 2), (160000, 2), (160000, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write the code here\n",
    "train = data.sample(frac=0.8, replace=True)\n",
    "dev = data.sample(frac=0.1, replace=True)\n",
    "test = data.sample(frac=0.1, replace=True)\n",
    "\n",
    "train.shape, dev.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline is .5, because simply guessing will get ~50% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.) Use a LabelEncoder to convert the tweet column to numbers\n",
    "\n",
    "* I do this for you. Just run the following cells to see how well representing a full tweet as an index number works for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tbevan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1280000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train.polarity.as_matrix()\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280000, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leX = preprocessing.LabelEncoder()\n",
    "leX.fit(data.tweet) # use the original data df so all possibilities are encoded\n",
    "X = leX.transform(train.tweet)\n",
    "X = X.reshape(X.shape[0], 1)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(penalty='l2', solver='lbfgs')\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdev = leX.transform(dev.tweet)\n",
    "Xdev = Xdev.reshape(Xdev.shape[0], 1)\n",
    "ydev = dev.polarity.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49763125"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(model.predict(Xdev), ydev) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.) Analysis of LabelEncoder\n",
    "\n",
    "* How well does LabelEncoder perform compared to the baseline?\n",
    "* Why does it perform so poorly? What does it have to do with the way the features are represented?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is about the same as the baseline. It does so poorly because most tweets are unique and as such each tweet is encoded differently and there are no trends to learn from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.) one-hot encoding\n",
    "\n",
    "* Repeat the steps of preparing the test and dev data as in #4, only this time use one-hot vectors instead of the label encoder\n",
    "* Hint: do you want to represent the entire tweet as a vector, or each word? (Hint: use words to make the one-hot encoder, then sum them to represent the entire tweet)\n",
    "* Hint: try `get_dummies()`, alternatively use scikitlearn's OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(data.tweet.values)\n",
    "X = vectorizer.transform(train.tweet.values)\n",
    "y = train.polarity.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tbevan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=300, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(penalty='l2', solver='lbfgs', max_iter=300)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.828125"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = vectorizer.transform(test.tweet.values)\n",
    "ytest = test.polarity.values\n",
    "\n",
    "accuracy_score(model.predict(Xtest), ytest) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.) word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* download the `GoogleNews-vectors-negative300.bin` file from https://github.com/mmihaltz/word2vec-GoogleNews-vectors and unzip the file\n",
    "* load the file by running the cell below (you may need to pip install gensim and you may need to change the path to the file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = w.KeyedVectors.load_word2vec_format('D:\\GoogleNews-vectors-negative300.bin',binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can access vectors like a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09716797, -0.08496094,  0.27148438], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v['red'][:3] # show the first three values for the vector for 'red'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* vectors are length 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v['red'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Repeat the steps of preparing the test and dev data as in #4, only this time use w2v vectors\n",
    "* How to do you represent a tweet, which is multiple words, as a single vector? (Hint: try summing the vectors)\n",
    "* Note: w2v only has lower-cased words\n",
    "* Hint: if w2v doesn't have a word you are looking for, just ignore that word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vector(tweet):\n",
    "    vectors = []\n",
    "    for word in tweet.lower().split():\n",
    "        try:\n",
    "            vectors.append(w2v[word.strip()])\n",
    "        except:\n",
    "            pass\n",
    "    if len(vectors) > 1:\n",
    "        return np.array(vectors).sum(axis=0)\n",
    "    elif len(vectors) == 1:\n",
    "        return np.array(vectors)[0]\n",
    "    else:\n",
    "        return np.zeros(300, dtype='f4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train['tweet'].map(generate_vector).values\n",
    "X = np.array(X.tolist())\n",
    "y = train['polarity'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7328125"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = test.tweet.map(generate_vector).values\n",
    "Xtest = np.array(Xtest.tolist())\n",
    "ytest = test.polarity.values\n",
    "\n",
    "accuracy_score(model.predict(Xtest), ytest) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.) Comparing the three approaches\n",
    "\n",
    "* Now that you've tried things out on your `dev` set, train on your `train`+`dev` data and test on your `test` data for all three approaches and report the results. \n",
    "* Why do you think one-hot and word2vec worked better than the label encoder?\n",
    "* Did one-hot or word2vec work better? Why do you think that is the case?\n",
    "* What do you think would happen if you cleaned up the tweets (e.g., removed punctuation, emojis, etc.)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label encoder doesn't decompose the tweet into components, so there is no way to compare tweets that aren't the same. The other two are breaking the tweets into words, and as such can assign weights to specific words in the tweet.\n",
    "\n",
    "One-hot did better in all my tests. I suspect it is because it creates a value in the vector for each distinct word, while the word2vec has a constant vector size of 300. In addition, there are words that contain symbols or other strange spellings that don't appear in the word2vec database. As a result, the one-hot encoder has better precision than word2vec. That precision leads to better models.\n",
    "\n",
    "Cleaning up the tweets better would improve the cohesion of the data set, as words would no longer be seperated if they had a period after them, or if they started with a #. That should improve the accuracy and reduce the data set as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.) Compare Machine Learning Approaches\n",
    "\n",
    "* Instead of using LogisticRegression, try another classifier from [scikit-learn](http://scikit-learn.org/stable/supervised_learning.html#supervised-learning) or nltk (e.g., decision trees, multi-layer perceptron, SVM, or maximum entropy)\n",
    "* Compare the results to logistic regression. \n",
    "* Why do you think one approach works better than another?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(data.tweet.values)\n",
    "X = vectorizer.transform(train.tweet.values)\n",
    "y = train.polarity.values\n",
    "Xtest = vectorizer.transform(test.tweet.values)\n",
    "ytest = test.polarity.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = naive_bayes.BernoulliNB()\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81331875"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(model.predict(Xtest), ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to use the bernoulli naive bayes model, as it has almost as much accuracy as the logistic regression. It however trains in less than a second as opposed to the couple minutes that the logistic takes, so it's a pretty good trade off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.) Pre-process the text\n",
    "\n",
    "* Now pre-process the text by doing one or more of the following:\n",
    "  * stemming\n",
    "  * lemmatizing\n",
    "  * removing stop-words\n",
    "* Re-run questions #6, #7, and #9 with the now preprocessed text (i.e., redo the one-hot and word2vec steps, and compare the results with LogisticRegression and your chosen approach in #9)\n",
    "* Answer the following in a markdown cell:\n",
    "  * How might you restrucure your notebook and programming approach to allow you to perform different pre-processing and machine learning training/evaluation steps more systematically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function removes @mentions, urls, and removes some characters\n",
    "\n",
    "r1 = re.compile('@[0-9A-Za-z_\\-]+')\n",
    "r2 = re.compile('https?://[A-Za-z0-9@_\\-\\./]*')\n",
    "r3 = re.compile('[\\.,]')\n",
    "r4 = re.compile('!')\n",
    "r5 = re.compile('\\?')\n",
    "def clean_string(x):\n",
    "    x = r1.sub('', x)\n",
    "    x = r2.sub('', x)\n",
    "    x = r3.sub('', x)\n",
    "    x = r4.sub(' !', x)\n",
    "    x = r5.sub(' ?', x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def line_prep(line):\n",
    "    ret_str = ''\n",
    "    for word in clean_string(line).lower().split():\n",
    "        ret_str = ret_str + \" \" + lemmatizer.lemmatize(word)\n",
    "    return ret_str\n",
    "\n",
    "# Map cleaning function\n",
    "data_clean = data.tweet.map(lambda x : clean_string(x).lower())\n",
    "full_words = set()\n",
    "for tweet in data_clean.values:\n",
    "    for word in tweet.split():\n",
    "        full_words.add(lemmatizer.lemmatize(word))\n",
    "        \n",
    "prepped = list(full_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above I'm using regex to clean up some things and then the wordnet lemmatizer to reduce the words to their bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(prepped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepX = train.tweet.map(line_prep)\n",
    "X = vectorizer.transform(prepX.values)\n",
    "y = train.polarity.values\n",
    "prepXtest = test.tweet.map(line_prep)\n",
    "Xtest = vectorizer.transform(prepXtest.values)\n",
    "ytest = test.polarity.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one-hot logistic regression and Bernoulli naive bayes both use these x and y sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tbevan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81513125"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(penalty='l2', solver='lbfgs', max_iter=500)\n",
    "model.fit(X,y)\n",
    "accuracy_score(model.predict(Xtest), ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cleaned up data does slightly worse than the raw data. This could be due to the fact that some of the variation that's being removed is actually meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74520625"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xw2v = prepX.map(generate_vector).values\n",
    "Xw2v = np.array(Xw2v.tolist())\n",
    "Xw2vtest = prepXtest.map(generate_vector).values\n",
    "Xw2vtest = np.array(Xw2vtest.tolist())\n",
    "model = linear_model.LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n",
    "model.fit(Xw2v, y)\n",
    "accuracy_score(model.predict(Xw2vtest), ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word2vec does better however, probably due to the fact that the cleaned up and lemmatized words are more likely to be in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79548125"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = naive_bayes.BernoulliNB()\n",
    "model.fit(X,y)\n",
    "accuracy_score(model.predict(Xtest), ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bernoulli does slightly worse, in line with the first model.\n",
    "\n",
    "My dataset generation and cleaning setups are not consistent, and some of the steps could be reduced to less block to make restarting after exiting simpler. Some of them are in functions and some are being done by hand. I should fix that to make it easier to use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
